{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install gensim scikit-learn datasets\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "re1FPQH6RLAH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4426c26c"
      },
      "source": [
        "## Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZKIXPdfhqHH",
        "outputId": "9733b28c-708a-4f23-d480-8ab6253aae53"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")\n",
        "train_dataset = dataset['train']\n",
        "test_dataset = dataset['validation']\n",
        "\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(test_dataset)}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 9543\n",
            "Validation dataset size: 2388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cfa61d5"
      },
      "source": [
        "## Implement textclassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2813cea"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer as SklearnTfidfVectorizer\n",
        "\n",
        "class Vectorizer:\n",
        "    def fit_transform(self, documents):\n",
        "        raise NotImplementedError(\"Subclass must implement abstract method\")\n",
        "\n",
        "class TfidfVectorizer(Vectorizer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.vectorizer = SklearnTfidfVectorizer(**kwargs)\n",
        "\n",
        "    def fit_transform(self, documents):\n",
        "        return self.vectorizer.fit_transform(documents)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d0a30c0"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "class TextClassifier:\n",
        "    \"\"\"Text classifier using Logistic Regression.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.model = LogisticRegression()\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"Fits the Logistic Regression model.\"\"\"\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"Makes predictions using the fitted model.\"\"\"\n",
        "        return self.model.predict(X_test)\n",
        "\n",
        "    def evaluate(self, y_true, y_pred):\n",
        "        \"\"\"Prints the classification report.\"\"\"\n",
        "        print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b0f9dd3"
      },
      "source": [
        "## Train and evaluate\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b44df7f",
        "outputId": "9d8a876c-f153-4fa4-cf85-55a5d0b73c01"
      },
      "source": [
        "train_texts = [item['text'] for item in train_dataset]\n",
        "train_labels = [item['label'] for item in train_dataset]\n",
        "val_texts = [item['text'] for item in test_dataset]\n",
        "val_labels = [item['label'] for item in test_dataset]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "X_val = vectorizer.vectorizer.transform(val_texts) # Use transform on validation data\n",
        "\n",
        "classifier = TextClassifier()\n",
        "classifier.fit(X_train, train_labels)\n",
        "predictions = classifier.predict(X_val)\n",
        "classifier.evaluate(val_labels, predictions)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.44      0.56       347\n",
            "           1       0.77      0.56      0.65       475\n",
            "           2       0.81      0.96      0.88      1566\n",
            "\n",
            "    accuracy                           0.80      2388\n",
            "   macro avg       0.79      0.65      0.70      2388\n",
            "weighted avg       0.80      0.80      0.79      2388\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97cabd2c"
      },
      "source": [
        "## Improve preprocessing and feature selection\n",
        "\n",
        "Apply noise filtering and vocabulary reduction techniques to the text data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91bc5f6c",
        "outputId": "e64dc4cc-54ed-408d-e5b1-d1eb149b2d8b"
      },
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(documents):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    processed_docs = []\n",
        "    for doc in documents:\n",
        "        # to lowercase + remove punctuation, num, stopwords + apply lemmatization\n",
        "        doc = doc.lower()\n",
        "        doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
        "        doc = re.sub(r'\\d+', '', doc)\n",
        "        words = doc.split()\n",
        "        words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "        processed_docs.append(' '.join(words))\n",
        "    return processed_docs\n",
        "\n",
        "train_texts_processed = preprocess_text(train_texts)\n",
        "val_texts_processed = preprocess_text(val_texts)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5D25fPJkQz0"
      },
      "source": [
        "new_vectorizer = TfidfVectorizer(max_df=0.95, min_df=5, max_features=10000)\n",
        "X_train_processed = new_vectorizer.fit_transform(train_texts_processed)\n",
        "X_val_processed = new_vectorizer.vectorizer.transform(val_texts_processed)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcfaaa90"
      },
      "source": [
        "#Experiment with more complex model architectures\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "gb_model = GradientBoostingClassifier()\n",
        "mlp_model = MLPClassifier(max_iter=1000)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ababca7",
        "outputId": "b80ac649-1d7c-4618-b60d-3bf85a5c5c69"
      },
      "source": [
        "print(\"Evaluating Multinomial Naive Bayes Model:\")\n",
        "nb_model.fit(X_train_processed, train_labels)\n",
        "nb_predictions = nb_model.predict(X_val_processed)\n",
        "print(classification_report(val_labels, nb_predictions))\n",
        "\n",
        "print(\"\\nEvaluating Gradient Boosting Classifier Model:\")\n",
        "gb_model.fit(X_train_processed, train_labels)\n",
        "gb_predictions = gb_model.predict(X_val_processed)\n",
        "print(classification_report(val_labels, gb_predictions))\n",
        "\n",
        "print(\"\\nEvaluating MLP Classifier Model:\")\n",
        "mlp_model.fit(X_train_processed, train_labels)\n",
        "mlp_predictions = mlp_model.predict(X_val_processed)\n",
        "print(classification_report(val_labels, mlp_predictions))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Multinomial Naive Bayes Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.27      0.40       347\n",
            "           1       0.72      0.48      0.58       475\n",
            "           2       0.77      0.97      0.86      1566\n",
            "\n",
            "    accuracy                           0.77      2388\n",
            "   macro avg       0.76      0.57      0.61      2388\n",
            "weighted avg       0.77      0.77      0.74      2388\n",
            "\n",
            "\n",
            "Evaluating Gradient Boosting Classifier Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.25      0.39       347\n",
            "           1       0.86      0.35      0.49       475\n",
            "           2       0.74      0.99      0.84      1566\n",
            "\n",
            "    accuracy                           0.75      2388\n",
            "   macro avg       0.82      0.53      0.58      2388\n",
            "weighted avg       0.78      0.75      0.71      2388\n",
            "\n",
            "\n",
            "Evaluating MLP Classifier Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.57      0.57       347\n",
            "           1       0.63      0.65      0.64       475\n",
            "           2       0.84      0.84      0.84      1566\n",
            "\n",
            "    accuracy                           0.76      2388\n",
            "   macro avg       0.68      0.68      0.68      2388\n",
            "weighted avg       0.76      0.76      0.76      2388\n",
            "\n"
          ]
        }
      ]
    }
  ]
}